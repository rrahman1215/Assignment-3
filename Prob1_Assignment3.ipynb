{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rrahman1215/Assignment-3/blob/main/Prob1_Assignment3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RFrwPgD4wKSS"
      },
      "source": [
        "%load_ext tensorboard\n",
        "\n",
        "from datetime import datetime\n",
        "from packaging import version\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "import tensorboard\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = keras.datasets.mnist.load_data()\n",
        "train_images = train_images / 255.0\n",
        "\n",
        "# train_images.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bicE_9g7wphh",
        "outputId": "4b94814d-7410-49b2-96f8-3540a996811c"
      },
      "source": [
        "################ part 1 ########################\n",
        "\n",
        "x_train = train_images.reshape(-1, 28, 28, 1) #add an additional dimension to represent the single-channel\n",
        "x_test = test_images.reshape(-1, 28, 28, 1)\n",
        "\n",
        "cnn_model = tf.keras.models.Sequential()\n",
        "cnn_model.add(tf.keras.layers.Conv2D(6, (3, 3), padding='same', activation='relu'))             #layer 1\n",
        "cnn_model.add(tf.keras.layers.Conv2D(12, (3, 3), padding='same', activation='relu'))              #layer 2\n",
        "cnn_model.add(tf.keras.layers.Conv2D(16, (3, 3), strides=2, padding='same', activation='relu')) #layer 3\n",
        "\n",
        "cnn_model.add(tf.keras.layers.Conv2D(24, (3, 3), padding='same', activation='relu')) #layer 4\n",
        "cnn_model.add(tf.keras.layers.Conv2D(32, (3, 3), padding='same', activation='relu'))            #layer 5\n",
        "cnn_model.add(tf.keras.layers.Conv2D(48, (3, 3), strides=2, padding='same', activation='relu')) #layer 6\n",
        "\n",
        "cnn_model.add(tf.keras.layers.Conv2D(56, (3, 3), padding='same', activation='relu'))                #layer 7\n",
        "cnn_model.add(tf.keras.layers.Conv2D(64, (3, 3), strides=2, padding='same', activation='relu'))     #layer 8\n",
        "cnn_model.add(tf.keras.layers.Conv2D(100, (3, 3), strides=2, padding='same', activation='relu'))      #layer 9\n",
        "\n",
        "cnn_model.add(tf.keras.layers.Conv2D(128, (3, 3), strides=2, padding='same', activation='relu')) #layer 10\n",
        "\n",
        "cnn_model.add(tf.keras.layers.Flatten())\n",
        "cnn_model.add(tf.keras.layers.Dense(256))\n",
        "cnn_model.add(tf.keras.layers.Activation('relu'))\n",
        "cnn_model.add(tf.keras.layers.Dense(10))\n",
        "cnn_model.add(tf.keras.layers.Activation('softmax'))\n",
        "\n",
        "\n",
        "\n",
        "######################### Hyper parameters ########################\n",
        "batch_size = 32\n",
        "epochs = 1\n",
        "choose_learning_rate = 0.0001\n",
        "optim = tf.keras.optimizers.SGD(learning_rate=choose_learning_rate)      #SGD\n",
        "optimizer_name = 'SGD'\n",
        "#optim = keras.optimizers.Adam(learning_rate=choose_learning_rate)      #adam\n",
        "#optimizer_name = 'Adam'\n",
        "#optim = tf.keras.optimizers.RMSprop(learning_rate=choose_learning_rate)  #RMS prop\n",
        "#optimizer_name = 'RMSprop'\n",
        "##################################################################\n",
        "\n",
        "\n",
        "cnn_model.compile(loss='sparse_categorical_crossentropy', optimizer=optim, metrics=['accuracy'])\n",
        "cnn_model.build(input_shape=(1,28,28,1))\n",
        "cnn_model.summary()\n",
        "\n",
        "print(optimizer_name, batch_size, choose_learning_rate)\n",
        "logdir=\"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n",
        "\n",
        "\n",
        "\n",
        "# logdir=\"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "# tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n",
        "\n",
        "model1 = cnn_model\n",
        "# Train the model.\n",
        "model1.fit(\n",
        "     x_train,\n",
        "     train_labels, \n",
        "     batch_size=batch_size,\n",
        "     epochs=epochs, \n",
        "     callbacks=[tensorboard_callback])\n",
        "\n",
        "print('Evaluate with test data:')\n",
        "score = model1.evaluate(x_test, test_labels)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_30 (Conv2D)          (1, 28, 28, 6)            60        \n",
            "                                                                 \n",
            " conv2d_31 (Conv2D)          (1, 28, 28, 12)           660       \n",
            "                                                                 \n",
            " conv2d_32 (Conv2D)          (1, 14, 14, 16)           1744      \n",
            "                                                                 \n",
            " conv2d_33 (Conv2D)          (1, 14, 14, 24)           3480      \n",
            "                                                                 \n",
            " conv2d_34 (Conv2D)          (1, 14, 14, 32)           6944      \n",
            "                                                                 \n",
            " conv2d_35 (Conv2D)          (1, 7, 7, 48)             13872     \n",
            "                                                                 \n",
            " conv2d_36 (Conv2D)          (1, 7, 7, 56)             24248     \n",
            "                                                                 \n",
            " conv2d_37 (Conv2D)          (1, 4, 4, 64)             32320     \n",
            "                                                                 \n",
            " conv2d_38 (Conv2D)          (1, 2, 2, 100)            57700     \n",
            "                                                                 \n",
            " conv2d_39 (Conv2D)          (1, 1, 1, 128)            115328    \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (1, 128)                  0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (1, 256)                  33024     \n",
            "                                                                 \n",
            " activation_6 (Activation)   (1, 256)                  0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (1, 10)                   2570      \n",
            "                                                                 \n",
            " activation_7 (Activation)   (1, 10)                   0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 291,950\n",
            "Trainable params: 291,950\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "SGD 32 0.0001\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 2.3025 - accuracy: 0.1124\n",
            "Evaluate with test data:\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 2.3040 - accuracy: 0.1061\n",
            "Test loss: 2.304025888442993\n",
            "Test accuracy: 0.10610000044107437\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "JTXKs2X-KDOF",
        "outputId": "f3e75a34-16dc-435b-b2cd-b3a2c1c7d2d4"
      },
      "source": [
        "for optim_no in range(3):\n",
        "  for batch_no in range (3):\n",
        "    for learn_rate_no in range(3):\n",
        "    \n",
        "      # Learn rate\n",
        "      if learn_rate_no == 0:\n",
        "        choose_learning_rate = 0.0001\n",
        "      if learn_rate_no == 1:\n",
        "        choose_learning_rate = 0.001\n",
        "      if learn_rate_no == 2:\n",
        "        choose_learning_rate = 0.01\n",
        "      # Optimizers\n",
        "      if optim_no == 0:\n",
        "        optim = keras.optimizers.Adam(learning_rate=choose_learning_rate)      #adam\n",
        "        optimizer_name = 'Adam'\n",
        "      if optim_no == 1:\n",
        "        optim = tf.keras.optimizers.SGD(learning_rate=choose_learning_rate)      #SGD\n",
        "        optimizer_name = 'SGD'\n",
        "      if optim_no == 2: \n",
        "        optim = tf.keras.optimizers.RMSprop(learning_rate=choose_learning_rate)  #RMS prop\n",
        "        optimizer_name = 'RMSprop'\n",
        "\n",
        "      # Batch no\n",
        "      if batch_no == 0:\n",
        "        batch_size = 32\n",
        "      if batch_no == 1:\n",
        "        batch_size = 64\n",
        "      if batch_no == 2:\n",
        "        batch_size = 128\n",
        "     \n",
        "      epochs = 1\n",
        "\n",
        "      cnn_model.compile(loss='sparse_categorical_crossentropy', optimizer=optim, metrics=['accuracy'])\n",
        "      cnn_model.build(input_shape=(1,28,28,1))\n",
        "      #cnn_model.summary()\n",
        "\n",
        "      print(optimizer_name, batch_size, choose_learning_rate)\n",
        "      logdir=\"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "      tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n",
        "\n",
        "      model1 = cnn_model\n",
        "      # Train the model.\n",
        "      model1.fit(\n",
        "          x_train,\n",
        "          train_labels, \n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs, \n",
        "          callbacks=[tensorboard_callback])\n",
        "\n",
        "      print('Evaluate with test data:')\n",
        "      score = model1.evaluate(x_test, test_labels)\n",
        "      print('Test loss:', score[0])\n",
        "      print('Test accuracy:', score[1])\n",
        "      print('\\n')\n",
        "        \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adam 32 0.0001\n",
            "1875/1875 [==============================] - 11s 5ms/step - loss: 0.3988 - accuracy: 0.8757\n",
            "Evaluate with test data:\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 23.6150 - accuracy: 0.9452\n",
            "Test loss: 23.614992141723633\n",
            "Test accuracy: 0.9452000260353088\n",
            "\n",
            "\n",
            "Adam 32 0.001\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1315 - accuracy: 0.9606\n",
            "Evaluate with test data:\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 9.8774 - accuracy: 0.9808\n",
            "Test loss: 9.87738037109375\n",
            "Test accuracy: 0.9807999730110168\n",
            "\n",
            "\n",
            "Adam 32 0.01\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.3861 - accuracy: 0.9038\n",
            "Evaluate with test data:\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 60.9704 - accuracy: 0.7075\n",
            "Test loss: 60.970401763916016\n",
            "Test accuracy: 0.7074999809265137\n",
            "\n",
            "\n",
            "Adam 64 0.0001\n",
            "938/938 [==============================] - 7s 7ms/step - loss: 0.1830 - accuracy: 0.9505\n",
            "Evaluate with test data:\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 38.1991 - accuracy: 0.7877\n",
            "Test loss: 38.199092864990234\n",
            "Test accuracy: 0.7876999974250793\n",
            "\n",
            "\n",
            "Adam 64 0.001\n",
            "938/938 [==============================] - 7s 7ms/step - loss: 0.1030 - accuracy: 0.9712\n",
            "Evaluate with test data:\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 34.6344 - accuracy: 0.7853\n",
            "Test loss: 34.634429931640625\n",
            "Test accuracy: 0.7853000164031982\n",
            "\n",
            "\n",
            "Adam 64 0.01\n",
            "938/938 [==============================] - 7s 7ms/step - loss: 0.2182 - accuracy: 0.9465\n",
            "Evaluate with test data:\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 73.2480 - accuracy: 0.6308\n",
            "Test loss: 73.24803161621094\n",
            "Test accuracy: 0.6308000087738037\n",
            "\n",
            "\n",
            "Adam 128 0.0001\n",
            "469/469 [==============================] - 5s 8ms/step - loss: 0.1111 - accuracy: 0.9706\n",
            "Evaluate with test data:\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 65.0241 - accuracy: 0.6532\n",
            "Test loss: 65.02406311035156\n",
            "Test accuracy: 0.6531999707221985\n",
            "\n",
            "\n",
            "Adam 128 0.001\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.0804 - accuracy: 0.9779\n",
            "Evaluate with test data:\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 73.6649 - accuracy: 0.7083\n",
            "Test loss: 73.66493225097656\n",
            "Test accuracy: 0.708299994468689\n",
            "\n",
            "\n",
            "Adam 128 0.01\n",
            "469/469 [==============================] - 5s 8ms/step - loss: 0.1644 - accuracy: 0.9599\n",
            "Evaluate with test data:\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 132.8016 - accuracy: 0.4884\n",
            "Test loss: 132.8015899658203\n",
            "Test accuracy: 0.48840001225471497\n",
            "\n",
            "\n",
            "SGD 32 0.0001\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1204 - accuracy: 0.9691\n",
            "Evaluate with test data:\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 138.5218 - accuracy: 0.4980\n",
            "Test loss: 138.5217742919922\n",
            "Test accuracy: 0.49799999594688416\n",
            "\n",
            "\n",
            "SGD 32 0.001\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0971 - accuracy: 0.9743\n",
            "Evaluate with test data:\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 137.5649 - accuracy: 0.5089\n",
            "Test loss: 137.56488037109375\n",
            "Test accuracy: 0.508899986743927\n",
            "\n",
            "\n",
            "SGD 32 0.01\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0828 - accuracy: 0.9775\n",
            "Evaluate with test data:\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 142.6432 - accuracy: 0.4982\n",
            "Test loss: 142.64320373535156\n",
            "Test accuracy: 0.498199999332428\n",
            "\n",
            "\n",
            "SGD 64 0.0001\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 0.0711 - accuracy: 0.9798\n",
            "Evaluate with test data:\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 142.6321 - accuracy: 0.4978\n",
            "Test loss: 142.63206481933594\n",
            "Test accuracy: 0.49779999256134033\n",
            "\n",
            "\n",
            "SGD 64 0.001\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 0.0684 - accuracy: 0.9808\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-2f01e44e4de6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     46\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m           callbacks=[tensorboard_callback])\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Evaluate with test data:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aeRBp6hjOCuO",
        "outputId": "f6ce8d56-c9c7-4f79-ee63-a67329dc5396"
      },
      "source": [
        "################ Part 2 ########################\n",
        "\n",
        "x_train = train_images.reshape(-1, 28, 28, 1) #add an additional dimension to represent the single-channel\n",
        "x_test = test_images.reshape(-1, 28, 28, 1)\n",
        "\n",
        "cnn_model = tf.keras.models.Sequential()\n",
        "cnn_model.add(tf.keras.layers.Conv2D(40, (3, 3), padding='same', activation='relu'))             #layer 1\n",
        "cnn_model.add(tf.keras.layers.Conv2D(35, (3, 3), padding='same', activation='relu'))              #layer 2\n",
        "cnn_model.add(tf.keras.layers.Conv2D(30, (3, 3), strides=2, padding='same', activation='relu')) #layer 3\n",
        "\n",
        "cnn_model.add(tf.keras.layers.Conv2D(25, (3, 3), padding='same', activation='relu')) #layer 4\n",
        "cnn_model.add(tf.keras.layers.Conv2D(20, (3, 3), padding='same', activation='relu'))            #layer 5\n",
        "cnn_model.add(tf.keras.layers.Conv2D(16, (3, 3), strides=2, padding='same', activation='relu')) #layer 6\n",
        "\n",
        "cnn_model.add(tf.keras.layers.Conv2D(12, (3, 3), padding='same', activation='relu'))                #layer 7\n",
        "cnn_model.add(tf.keras.layers.Conv2D(8, (3, 3), strides=2, padding='same', activation='relu'))     #layer 8\n",
        "cnn_model.add(tf.keras.layers.Conv2D(4, (3, 3), strides=2, padding='same', activation='relu'))      #layer 9\n",
        "\n",
        "cnn_model.add(tf.keras.layers.Conv2D(2, (3, 3), strides=2, padding='same', activation='relu')) #layer 10\n",
        "\n",
        "cnn_model.add(tf.keras.layers.Flatten())\n",
        "cnn_model.add(tf.keras.layers.Dense(64))\n",
        "cnn_model.add(tf.keras.layers.Activation('relu'))\n",
        "cnn_model.add(tf.keras.layers.Dense(10))\n",
        "cnn_model.add(tf.keras.layers.Activation('softmax'))\n",
        "\n",
        "batch_size = 64\n",
        "epochs = 1\n",
        "choose_learning_rate = 0.0001\n",
        "# optim = keras.optimizers.Adam(learning_rate=choose_learning_rate)      #adam\n",
        "# optim = tf.keras.optimizers.SGD(learning_rate=choose_learning_rate)      #SGD\n",
        "optim = tf.keras.optimizers.RMSprop(learning_rate=choose_learning_rate)  #RMS prop\n",
        "\n",
        "cnn_model.compile(loss='sparse_categorical_crossentropy', optimizer=optim, metrics=['accuracy'])\n",
        "cnn_model.build(input_shape=(1,28,28,1))\n",
        "cnn_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_50 (Conv2D)          (1, 28, 28, 40)           400       \n",
            "                                                                 \n",
            " conv2d_51 (Conv2D)          (1, 28, 28, 35)           12635     \n",
            "                                                                 \n",
            " conv2d_52 (Conv2D)          (1, 14, 14, 30)           9480      \n",
            "                                                                 \n",
            " conv2d_53 (Conv2D)          (1, 14, 14, 25)           6775      \n",
            "                                                                 \n",
            " conv2d_54 (Conv2D)          (1, 14, 14, 20)           4520      \n",
            "                                                                 \n",
            " conv2d_55 (Conv2D)          (1, 7, 7, 16)             2896      \n",
            "                                                                 \n",
            " conv2d_56 (Conv2D)          (1, 7, 7, 12)             1740      \n",
            "                                                                 \n",
            " conv2d_57 (Conv2D)          (1, 4, 4, 8)              872       \n",
            "                                                                 \n",
            " conv2d_58 (Conv2D)          (1, 2, 2, 4)              292       \n",
            "                                                                 \n",
            " conv2d_59 (Conv2D)          (1, 1, 1, 2)              74        \n",
            "                                                                 \n",
            " flatten_5 (Flatten)         (1, 2)                    0         \n",
            "                                                                 \n",
            " dense_10 (Dense)            (1, 64)                   192       \n",
            "                                                                 \n",
            " activation_10 (Activation)  (1, 64)                   0         \n",
            "                                                                 \n",
            " dense_11 (Dense)            (1, 10)                   650       \n",
            "                                                                 \n",
            " activation_11 (Activation)  (1, 10)                   0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 40,526\n",
            "Trainable params: 40,526\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 693
        },
        "id": "UVKm5LROO9lg",
        "outputId": "3c3c967a-38d1-45ac-a3ca-6945863d1a31"
      },
      "source": [
        "for optim_no in range(3):\n",
        "  for learn_rate_no in range (2):\n",
        "    for batch_no in range(2):\n",
        "    \n",
        "      # Learn rate\n",
        "      if learn_rate_no == 0:\n",
        "        choose_learning_rate = 0.0001\n",
        "      if learn_rate_no == 1:\n",
        "        choose_learning_rate = 0.001\n",
        "\n",
        "      # Optimizers\n",
        "      if optim_no == 0:\n",
        "        optim = keras.optimizers.Adam(learning_rate=choose_learning_rate)      #adam\n",
        "        optimizer_name = 'Adam'\n",
        "      if optim_no == 1:\n",
        "        optim = tf.keras.optimizers.SGD(learning_rate=choose_learning_rate)      #SGD\n",
        "        optimizer_name = 'SGD'\n",
        "      if optim_no == 2: \n",
        "        optim = tf.keras.optimizers.RMSprop(learning_rate=choose_learning_rate)  #RMS prop\n",
        "        optimizer_name = 'RMSprop'\n",
        "\n",
        "      # Batch no\n",
        "      if batch_no == 0:\n",
        "        batch_size = 64\n",
        "      if batch_no == 1:\n",
        "        batch_size = 256\n",
        "      \n",
        "      epochs = 1\n",
        "\n",
        "      cnn_model.compile(loss='sparse_categorical_crossentropy', optimizer=optim, metrics=['accuracy'])\n",
        "      cnn_model.build(input_shape=(1,28,28,1))\n",
        "      # cnn_model.summary()\n",
        "\n",
        "      print(optimizer_name, batch_size, choose_learning_rate)\n",
        "      logdir=\"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "      tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n",
        "\n",
        "      model1 = cnn_model\n",
        "      # Train the model.\n",
        "      model1.fit(\n",
        "          x_train,\n",
        "          train_labels, \n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs, \n",
        "          callbacks=[tensorboard_callback])\n",
        "\n",
        "      print('Evaluate with test data:')\n",
        "      score = model1.evaluate(x_test, test_labels)\n",
        "      print('Test loss:', score[0])\n",
        "      print('Test accuracy:', score[1])\n",
        "      print('\\n')\n",
        "        \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adam 64 0.0001\n",
            "938/938 [==============================] - 8s 7ms/step - loss: 1.5990 - accuracy: 0.3583\n",
            "Evaluate with test data:\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 115.0203 - accuracy: 0.4728\n",
            "Test loss: 115.02030944824219\n",
            "Test accuracy: 0.47279998660087585\n",
            "\n",
            "\n",
            "Adam 256 0.0001\n",
            "235/235 [==============================] - 5s 19ms/step - loss: 1.1935 - accuracy: 0.5318\n",
            "Evaluate with test data:\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 108.3494 - accuracy: 0.5354\n",
            "Test loss: 108.34937286376953\n",
            "Test accuracy: 0.5353999733924866\n",
            "\n",
            "\n",
            "Adam 64 0.001\n",
            "626/938 [===================>..........] - ETA: 2s - loss: 1.0406 - accuracy: 0.5885"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-a58c77eda34e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     43\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m           callbacks=[tensorboard_callback])\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Evaluate with test data:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1399\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_stop_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1400\u001b[0m           \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initial_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_load_initial_step_from_ckpt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1401\u001b[0;31m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1402\u001b[0m             with tf.profiler.experimental.Trace(\n\u001b[1;32m   1403\u001b[0m                 \u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36msteps\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1246\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_insufficient_data\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Set by `catch_stop_iteration`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1247\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1248\u001b[0;31m       \u001b[0moriginal_spe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_steps_per_execution\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1249\u001b[0m       can_run_full_execution = (\n\u001b[1;32m   1250\u001b[0m           \u001b[0moriginal_spe\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    635\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 637\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    638\u001b[0m     raise NotImplementedError(\n\u001b[1;32m    639\u001b[0m         \"numpy() is only available when eager execution is enabled.\")\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1157\u001b[0m     \"\"\"\n\u001b[1;32m   1158\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1159\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1160\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1123\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1125\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1126\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DQTZABjwQLwL",
        "outputId": "8cd4e764-3abc-41ad-e42d-081612ba1197"
      },
      "source": [
        "################ Part 3 ########################\n",
        "\n",
        "x_train = train_images.reshape(-1, 28, 28, 1) #add an additional dimension to represent the single-channel\n",
        "x_test = test_images.reshape(-1, 28, 28, 1)\n",
        "\n",
        "cnn_model = tf.keras.models.Sequential()\n",
        "cnn_model.add(tf.keras.layers.Conv2D(4, (3, 3), padding='same', activation='relu'))             #layer 1\n",
        "cnn_model.add(tf.keras.layers.Conv2D(8, (3, 3), padding='same', activation='relu'))              #layer 2\n",
        "cnn_model.add(tf.keras.layers.Conv2D(16, (3, 3), strides=2, padding='same', activation='relu')) #layer 3\n",
        "\n",
        "cnn_model.add(tf.keras.layers.Conv2D(25, (3, 3), padding='same', activation='relu')) #layer 4\n",
        "cnn_model.add(tf.keras.layers.Conv2D(32, (3, 3), padding='same', activation='relu'))            #layer 5\n",
        "cnn_model.add(tf.keras.layers.Conv2D(25, (3, 3), strides=2, padding='same', activation='relu')) #layer 6\n",
        "\n",
        "cnn_model.add(tf.keras.layers.Conv2D(16, (3, 3), padding='same', activation='relu'))                #layer 7\n",
        "cnn_model.add(tf.keras.layers.Conv2D(8, (3, 3), strides=2, padding='same', activation='relu'))     #layer 8\n",
        "cnn_model.add(tf.keras.layers.Conv2D(4, (3, 3), strides=2, padding='same', activation='relu'))      #layer 9\n",
        "\n",
        "cnn_model.add(tf.keras.layers.Conv2D(2, (3, 3), strides=2, padding='same', activation='relu')) #layer 10\n",
        "\n",
        "cnn_model.add(tf.keras.layers.Flatten())\n",
        "cnn_model.add(tf.keras.layers.Dense(64))\n",
        "cnn_model.add(tf.keras.layers.Activation('relu'))\n",
        "cnn_model.add(tf.keras.layers.Dense(10))\n",
        "cnn_model.add(tf.keras.layers.Activation('softmax'))\n",
        "\n",
        "\n",
        "batch_size = 64\n",
        "epochs = 1\n",
        "choose_learning_rate = 0.0001\n",
        "# optim = keras.optimizers.Adam(learning_rate=choose_learning_rate)      #adam\n",
        "# optim = tf.keras.optimizers.SGD(learning_rate=choose_learning_rate)      #SGD\n",
        "optim = tf.keras.optimizers.RMSprop(learning_rate=choose_learning_rate)  #RMS prop\n",
        "\n",
        "\n",
        "\n",
        "cnn_model.compile(loss='sparse_categorical_crossentropy', optimizer=optim, metrics=['accuracy'])\n",
        "cnn_model.build(input_shape=(1,28,28,1))\n",
        "cnn_model.summary()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_10 (Conv2D)           (1, 28, 28, 4)            40        \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (1, 28, 28, 8)            296       \n",
            "_________________________________________________________________\n",
            "conv2d_12 (Conv2D)           (1, 14, 14, 16)           1168      \n",
            "_________________________________________________________________\n",
            "conv2d_13 (Conv2D)           (1, 14, 14, 25)           3625      \n",
            "_________________________________________________________________\n",
            "conv2d_14 (Conv2D)           (1, 14, 14, 32)           7232      \n",
            "_________________________________________________________________\n",
            "conv2d_15 (Conv2D)           (1, 7, 7, 25)             7225      \n",
            "_________________________________________________________________\n",
            "conv2d_16 (Conv2D)           (1, 7, 7, 16)             3616      \n",
            "_________________________________________________________________\n",
            "conv2d_17 (Conv2D)           (1, 4, 4, 8)              1160      \n",
            "_________________________________________________________________\n",
            "conv2d_18 (Conv2D)           (1, 2, 2, 4)              292       \n",
            "_________________________________________________________________\n",
            "conv2d_19 (Conv2D)           (1, 1, 1, 2)              74        \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (1, 2)                    0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (1, 64)                   192       \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (1, 64)                   0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (1, 10)                   650       \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (1, 10)                   0         \n",
            "=================================================================\n",
            "Total params: 25,570\n",
            "Trainable params: 25,570\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FuPcSNOeclMl",
        "outputId": "ed2d99bb-e2f1-4c12-885b-c5854d3ecf07"
      },
      "source": [
        "for optim_no in range(3):\n",
        "  for learn_rate_no in range (2):\n",
        "    for batch_no in range(2):\n",
        "    \n",
        "      # Learn rate\n",
        "      if learn_rate_no == 0:\n",
        "        choose_learning_rate = 0.0001\n",
        "      if learn_rate_no == 1:\n",
        "        choose_learning_rate = 0.001\n",
        "\n",
        "      # Optimizers\n",
        "      if optim_no == 0:\n",
        "        optim = keras.optimizers.Adam(learning_rate=choose_learning_rate)      #adam\n",
        "        optimizer_name = 'Adam'\n",
        "      if optim_no == 1:\n",
        "        optim = tf.keras.optimizers.SGD(learning_rate=choose_learning_rate)      #SGD\n",
        "        optimizer_name = 'SGD'\n",
        "      if optim_no == 2: \n",
        "        optim = tf.keras.optimizers.RMSprop(learning_rate=choose_learning_rate)  #RMS prop\n",
        "        optimizer_name = 'RMSprop'\n",
        "\n",
        "      # Batch no\n",
        "      if batch_no == 0:\n",
        "        batch_size = 64\n",
        "      if batch_no == 1:\n",
        "        batch_size = 256\n",
        "      \n",
        "      epochs = 1\n",
        "\n",
        "      cnn_model.compile(loss='sparse_categorical_crossentropy', optimizer=optim, metrics=['accuracy'])\n",
        "      cnn_model.build(input_shape=(1,28,28,1))\n",
        "      # cnn_model.summary()\n",
        "\n",
        "      print(optimizer_name, batch_size, choose_learning_rate)\n",
        "      logdir=\"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "      tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n",
        "\n",
        "      model1 = cnn_model\n",
        "      # Train the model.\n",
        "      model1.fit(\n",
        "          x_train,\n",
        "          train_labels, \n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs, \n",
        "          callbacks=[tensorboard_callback])\n",
        "\n",
        "      print('Evaluate with test data:')\n",
        "      score = model1.evaluate(x_test, test_labels)\n",
        "      print('Test loss:', score[0])\n",
        "      print('Test accuracy:', score[1])\n",
        "      print('\\n')\n",
        "        \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adam 64 0.0001\n",
            "938/938 [==============================] - 90s 95ms/step - loss: 1.9518 - accuracy: 0.2232\n",
            "Evaluate with test data:\n",
            "313/313 [==============================] - 6s 17ms/step - loss: 111.9258 - accuracy: 0.3568\n",
            "Test loss: 111.92576599121094\n",
            "Test accuracy: 0.35679998993873596\n",
            "\n",
            "\n",
            "Adam 256 0.0001\n",
            "235/235 [==============================] - 77s 323ms/step - loss: 1.4650 - accuracy: 0.4576\n",
            "Evaluate with test data:\n",
            "313/313 [==============================] - 5s 17ms/step - loss: 99.3279 - accuracy: 0.4877\n",
            "Test loss: 99.3279037475586\n",
            "Test accuracy: 0.4876999855041504\n",
            "\n",
            "\n",
            "Adam 64 0.001\n",
            "938/938 [==============================] - 90s 96ms/step - loss: 0.9732 - accuracy: 0.6675\n",
            "Evaluate with test data:\n",
            "313/313 [==============================] - 5s 17ms/step - loss: 161.5435 - accuracy: 0.6705\n",
            "Test loss: 161.54345703125\n",
            "Test accuracy: 0.6704999804496765\n",
            "\n",
            "\n",
            "Adam 256 0.001\n",
            "235/235 [==============================] - 77s 326ms/step - loss: 0.4684 - accuracy: 0.8718\n",
            "Evaluate with test data:\n",
            "313/313 [==============================] - 6s 18ms/step - loss: 146.3676 - accuracy: 0.7200\n",
            "Test loss: 146.3676300048828\n",
            "Test accuracy: 0.7200000286102295\n",
            "\n",
            "\n",
            "SGD 64 0.0001\n",
            "938/938 [==============================] - 86s 91ms/step - loss: 0.3519 - accuracy: 0.9100\n",
            "Evaluate with test data:\n",
            "313/313 [==============================] - 6s 17ms/step - loss: 144.4120 - accuracy: 0.7152\n",
            "Test loss: 144.41201782226562\n",
            "Test accuracy: 0.7152000069618225\n",
            "\n",
            "\n",
            "SGD 256 0.0001\n",
            "235/235 [==============================] - 76s 320ms/step - loss: 0.3453 - accuracy: 0.9123\n",
            "Evaluate with test data:\n",
            "313/313 [==============================] - 6s 18ms/step - loss: 142.4155 - accuracy: 0.7149\n",
            "Test loss: 142.41546630859375\n",
            "Test accuracy: 0.714900016784668\n",
            "\n",
            "\n",
            "SGD 64 0.001\n",
            "938/938 [==============================] - 94s 99ms/step - loss: 0.3607 - accuracy: 0.9062\n",
            "Evaluate with test data:\n",
            "313/313 [==============================] - 6s 18ms/step - loss: 158.7091 - accuracy: 0.6979\n",
            "Test loss: 158.7090606689453\n",
            "Test accuracy: 0.6978999972343445\n",
            "\n",
            "\n",
            "SGD 256 0.001\n",
            "235/235 [==============================] - 78s 329ms/step - loss: 0.3282 - accuracy: 0.9171\n",
            "Evaluate with test data:\n",
            "313/313 [==============================] - 6s 18ms/step - loss: 139.8664 - accuracy: 0.7215\n",
            "Test loss: 139.86639404296875\n",
            "Test accuracy: 0.7214999794960022\n",
            "\n",
            "\n",
            "RMSprop 64 0.0001\n",
            "938/938 [==============================] - 94s 99ms/step - loss: 0.3214 - accuracy: 0.9176\n",
            "Evaluate with test data:\n",
            "313/313 [==============================] - 6s 18ms/step - loss: 144.9715 - accuracy: 0.7232\n",
            "Test loss: 144.9714813232422\n",
            "Test accuracy: 0.7232000231742859\n",
            "\n",
            "\n",
            "RMSprop 256 0.0001\n",
            "235/235 [==============================] - 78s 329ms/step - loss: 0.2970 - accuracy: 0.9249\n",
            "Evaluate with test data:\n",
            "313/313 [==============================] - 6s 18ms/step - loss: 146.7690 - accuracy: 0.7274\n",
            "Test loss: 146.76898193359375\n",
            "Test accuracy: 0.727400004863739\n",
            "\n",
            "\n",
            "RMSprop 64 0.001\n",
            "938/938 [==============================] - 89s 93ms/step - loss: 0.3762 - accuracy: 0.8984\n",
            "Evaluate with test data:\n",
            "313/313 [==============================] - 6s 18ms/step - loss: 188.4447 - accuracy: 0.7096\n",
            "Test loss: 188.44473266601562\n",
            "Test accuracy: 0.7095999717712402\n",
            "\n",
            "\n",
            "RMSprop 256 0.001\n",
            "235/235 [==============================] - 76s 320ms/step - loss: 0.2385 - accuracy: 0.9396\n",
            "Evaluate with test data:\n",
            "313/313 [==============================] - 6s 18ms/step - loss: 176.8238 - accuracy: 0.7237\n",
            "Test loss: 176.82383728027344\n",
            "Test accuracy: 0.7236999869346619\n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ]
}